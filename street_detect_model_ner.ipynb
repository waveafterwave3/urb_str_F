{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0cf0ed61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import json\n",
    "from spacy.training.example import Example\n",
    "from spacy.util import minibatch\n",
    "import random\n",
    "from spacy.scorer import Scorer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f52b1171",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file_path = 'streetdata_01.json'\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4fd38a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('На Жибек Жолы, дом 15, уже неделю не убирают мусор во дворе. Становится грязно.', {'entities': [(3, 13, 'Street'), (15, 21, 'NUM')]}), ('Абылай хана, 23 — освещение на улице не работает. Вечером темно, ходить страшно.', {'entities': [(0, 11, 'Street'), (13, 15, 'NUM')]})]\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DATA = []\n",
    "for item in data:\n",
    "    text = item['data']['Message']\n",
    "    entities = []\n",
    "    for annotation in item['annotations'][0]['result']:\n",
    "        start = annotation['value']['start']\n",
    "        end = annotation['value']['end']\n",
    "        label = annotation['value']['labels'][0]\n",
    "        entities.append((start, end, label))\n",
    "    TRAIN_DATA.append((text, {\"entities\": entities}))\n",
    "\n",
    "print(TRAIN_DATA[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "037e03b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"ru_core_news_sm\")\n",
    "ner = nlp.get_pipe(\"ner\")\n",
    "\n",
    "for _, annotations in TRAIN_DATA:\n",
    "    for ent in annotations.get(\"entities\"):\n",
    "        ner.add_label(ent[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7f6e3db",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tsoyvlad/anaconda3/lib/python3.11/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Назарбаева 5Г. Разметка на дороге вообще стерлась,...\" with entities \"[(0, 10, 'Street'), (11, 13, 'NUM')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/tsoyvlad/anaconda3/lib/python3.11/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Проблемы с водоснабжением, Гоголя, дом 12А.\" with entities \"[(27, 33, 'Street'), (39, 42, 'NUM')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/tsoyvlad/anaconda3/lib/python3.11/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Родостовца, 7 и Варламова, дом 3А. Двор зарос трав...\" with entities \"[(0, 10, 'Street'), (12, 13, 'NUM'), (16, 25, 'Str...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/tsoyvlad/anaconda3/lib/python3.11/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"В парке Ганди тротуарные плитки у входа выпирают, ...\" with entities \"[(0, 14, 'Park')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/tsoyvlad/anaconda3/lib/python3.11/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"По данному адресу уличного освещения нет, Родостов...\" with entities \"[(42, 52, 'Street'), (52, 55, 'NUM')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/tsoyvlad/anaconda3/lib/python3.11/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Байтурсынова, 16 и Богенбай батыра, дом 8А. Постоя...\" with entities \"[(0, 12, 'Street'), (14, 16, 'NUM'), (19, 34, 'Str...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/tsoyvlad/anaconda3/lib/python3.11/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Дети играют на разрушенной площадке, Байзакова 10А...\" with entities \"[(37, 46, 'Street'), (47, 50, 'NUM')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/tsoyvlad/anaconda3/lib/python3.11/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Вода часто отключается, Кабанбай батыра, дом 18А.\" with entities \"[(24, 39, 'Street'), (45, 48, 'NUM')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/tsoyvlad/anaconda3/lib/python3.11/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Варламова, дом 5, и Толе би, дом 18А. Парковка заб...\" with entities \"[(0, 9, 'Street'), (20, 27, 'Street'), (29, 36, 'N...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/tsoyvlad/anaconda3/lib/python3.11/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"В городе алматы, на улице брусилоского52 сломан св...\" with entities \"[(26, 38, 'Street'), (38, 40, 'NUM')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/tsoyvlad/anaconda3/lib/python3.11/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Возле улиц Кабанбай батыра/ Брусиловского, не видн...\" with entities \"[(11, 26, 'Street'), (28, 41, 'Street'), (0, 10, '...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/tsoyvlad/anaconda3/lib/python3.11/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Добрый день! Просим оказать содействие в решении н...\" with entities \"[(79, 89, 'Street'), (91, 94, 'NUM')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/tsoyvlad/anaconda3/lib/python3.11/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Кабанбай батыра, дом 17 и Богенбай батыра, дом 5А....\" with entities \"[(0, 15, 'Street'), (26, 41, 'Street'), (43, 49, '...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/tsoyvlad/anaconda3/lib/python3.11/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Улица Родостовца, дом 4, и Торгут Озала, дом 7А. Н...\" with entities \"[(6, 16, 'Street'), (27, 39, 'Street'), (41, 47, '...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/tsoyvlad/anaconda3/lib/python3.11/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Абая, 17-й дом. Проблемы с электричеством, лампы п...\" with entities \"[(0, 4, 'Street'), (6, 8, 'NUM')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/tsoyvlad/anaconda3/lib/python3.11/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Добрый день! Байсеитовой,36. Дворник уволился. Ког...\" with entities \"[(13, 24, 'Street'), (25, 27, 'NUM')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/tsoyvlad/anaconda3/lib/python3.11/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Байзакова и Толе би — сломаны лавочки возле автобу...\" with entities \"[(0, 9, 'Street'), (12, 20, 'Street')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/tsoyvlad/anaconda3/lib/python3.11/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"На Шарипова /Фурманова, нет отопления в домах 3 де...\" with entities \"[(3, 11, 'Street'), (13, 22, 'Street')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/tsoyvlad/anaconda3/lib/python3.11/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Добрый аечер! Можно попросить установить дополните...\" with entities \"[(85, 97, 'Street'), (99, 106, 'Street')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/tsoyvlad/anaconda3/lib/python3.11/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"В ЖК Комфорт, На улице айтекеби- тулебаева 87а\" with entities \"[(23, 31, 'Street'), (33, 42, 'Street'), (43, 46, ...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/tsoyvlad/anaconda3/lib/python3.11/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Сейфуллина -казыбек би \n",
      "Не горит именно зеленый св...\" with entities \"[(0, 10, 'Street'), (12, 22, 'Street')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/tsoyvlad/anaconda3/lib/python3.11/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"В Центральном парке напротив сцены всегда грязно, ...\" with entities \"[(0, 20, 'Park')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tsoyvlad/anaconda3/lib/python3.11/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Шагабутдинова Николская дом 88/ 5 неделю никого не...\" with entities \"[(0, 13, 'Street'), (14, 23, 'Street'), (24, 30, '...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/tsoyvlad/anaconda3/lib/python3.11/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"На улицах Кабанбай батыры/ Аносова нет уличного ос...\" with entities \"[(10, 25, 'Street'), (27, 34, 'Street')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/tsoyvlad/anaconda3/lib/python3.11/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Парк имени Ганди — на детской площадке небезопасны...\" with entities \"[(0, 17, 'Park')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/tsoyvlad/anaconda3/lib/python3.11/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"\"На улице Ленина,34, проблемы с водоснабжением. Во...\" with entities \"[(10, 16, 'Street'), (17, 19, 'NUM')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/tsoyvlad/anaconda3/lib/python3.11/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"На углу Родостовца и Байзакова нет нормальной разм...\" with entities \"[(0, 8, 'Peresechenie'), (8, 18, 'Street'), (21, 3...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/tsoyvlad/anaconda3/lib/python3.11/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Разбитый тротуар на улице Гоголя, дом 11А.\" with entities \"[(26, 32, 'Street'), (38, 41, 'NUM')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/tsoyvlad/anaconda3/lib/python3.11/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Добрый день! Исаева -Айтеке би, после ремонта трот...\" with entities \"[(13, 19, 'Street'), (21, 30, 'Street')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/tsoyvlad/anaconda3/lib/python3.11/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Улица Жибек Жолы, дом 4А, лестница поломана, стари...\" with entities \"[(6, 15, 'Street'), (22, 24, 'NUM')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/tsoyvlad/anaconda3/lib/python3.11/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Добрый день! Уже писала ранее о светофоре на Мурат...\" with entities \"[(45, 55, 'Street'), (83, 97, 'Street')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/tsoyvlad/anaconda3/lib/python3.11/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Нужен ремонт дороги на Толе би, дом 10А.\" with entities \"[(23, 30, 'Street'), (36, 39, 'NUM')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/tsoyvlad/anaconda3/lib/python3.11/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"\"Улица Ауэзова,56 — здесь упала ветка дерева на пр...\" with entities \"[(7, 14, 'Street'), (15, 17, 'NUM')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/tsoyvlad/anaconda3/lib/python3.11/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Назарбаева 3Б. Лестница в ужасном состоянии, даже ...\" with entities \"[(0, 10, 'Street'), (11, 13, 'NUM')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/tsoyvlad/anaconda3/lib/python3.11/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Назарбаева 13А. Лифт второй день не работает, сосе...\" with entities \"[(0, 10, 'Street'), (11, 14, 'NUM')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/tsoyvlad/anaconda3/lib/python3.11/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Возле этого дома уже 2месяц нет света, по улице Ку...\" with entities \"[(48, 58, 'Street'), (58, 60, 'NUM')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/tsoyvlad/anaconda3/lib/python3.11/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"По улице Аносова д.30 , 28, 26 37, 39, 41когда вкл...\" with entities \"[(9, 16, 'Street'), (17, 41, 'NUM'), (205, 207, 'N...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/tsoyvlad/anaconda3/lib/python3.11/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Богенбай батыра, 9 и Толе би, дом 11А. Тротуары вс...\" with entities \"[(0, 15, 'Street'), (17, 18, 'NUM'), (21, 28, 'Str...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/tsoyvlad/anaconda3/lib/python3.11/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Здравствуйте. Толе Би 178,178А нет отопления. С пя...\" with entities \"[(14, 21, 'Street'), (22, 25, 'NUM'), (26, 30, 'NU...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/tsoyvlad/anaconda3/lib/python3.11/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Сейчас тут же, Жумалиева /Кабанбай батыра обустраи...\" with entities \"[(15, 24, 'Street'), (26, 41, 'Street')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/tsoyvlad/anaconda3/lib/python3.11/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Здравствуйте.Ауезова 34.Долго нам наблюдать за это...\" with entities \"[(13, 20, 'Street'), (21, 23, 'NUM')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses at iteration 0: {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 2285.78585636703}\n",
      "Losses at iteration 1: {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 816.6105131774129}\n",
      "Losses at iteration 2: {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 558.3277106643404}\n",
      "Losses at iteration 3: {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 456.27556227042595}\n",
      "Losses at iteration 4: {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 398.2143917155371}\n",
      "Losses at iteration 5: {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 336.354144773628}\n",
      "Losses at iteration 6: {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 374.2538978840434}\n",
      "Losses at iteration 7: {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 289.24045866616365}\n",
      "Losses at iteration 8: {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 280.6083080416447}\n",
      "Losses at iteration 9: {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 278.9744712771923}\n",
      "Losses at iteration 10: {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 252.43519210610043}\n",
      "Losses at iteration 11: {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 242.10814478189894}\n",
      "Losses at iteration 12: {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 269.3509921016935}\n",
      "Losses at iteration 13: {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 226.26382925737477}\n",
      "Losses at iteration 14: {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 280.1718010225588}\n",
      "Losses at iteration 15: {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 187.35536869181962}\n",
      "Losses at iteration 16: {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 208.09097903219885}\n",
      "Losses at iteration 17: {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 217.8083593161579}\n",
      "Losses at iteration 18: {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 186.58652833404463}\n",
      "Losses at iteration 19: {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 215.610383108197}\n",
      "Losses at iteration 20: {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 196.3825453662952}\n",
      "Losses at iteration 21: {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 185.65653401224716}\n",
      "Losses at iteration 22: {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 187.35966556171817}\n",
      "Losses at iteration 23: {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 186.07079177423446}\n",
      "Losses at iteration 24: {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 182.85837190868426}\n",
      "Losses at iteration 25: {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 188.64476383411304}\n",
      "Losses at iteration 26: {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 169.91310744305852}\n",
      "Losses at iteration 27: {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 155.28328762325367}\n",
      "Losses at iteration 28: {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 164.8978155209123}\n",
      "Losses at iteration 29: {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 139.16183142006074}\n",
      "Losses at iteration 30: {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 160.17391004326674}\n",
      "Losses at iteration 31: {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 148.37805879366545}\n",
      "Losses at iteration 32: {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 149.21383665987122}\n",
      "Losses at iteration 33: {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 141.67339757270548}\n",
      "Losses at iteration 34: {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 145.71072982090737}\n",
      "Losses at iteration 35: {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 121.41359006171164}\n",
      "Losses at iteration 36: {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 148.4369636116217}\n",
      "Losses at iteration 37: {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 123.68715099894662}\n",
      "Losses at iteration 38: {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 129.63852911739878}\n",
      "Losses at iteration 39: {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 135.85751767690033}\n",
      "Losses at iteration 40: {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 111.32357621589328}\n",
      "Losses at iteration 41: {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 125.65826601041364}\n",
      "Losses at iteration 42: {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 112.31064513586287}\n",
      "Losses at iteration 43: {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 135.42676259967988}\n",
      "Losses at iteration 44: {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 140.01520244302785}\n",
      "Losses at iteration 45: {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 113.42941671139099}\n",
      "Losses at iteration 46: {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 113.48094300854956}\n",
      "Losses at iteration 47: {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 120.31867285452098}\n",
      "Losses at iteration 48: {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 91.50402506752322}\n",
      "Losses at iteration 49: {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 124.11521996555312}\n",
      "Losses at iteration 50: {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 115.21855845178838}\n",
      "Losses at iteration 51: {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 107.86825293385648}\n",
      "Losses at iteration 52: {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 118.7679096628353}\n",
      "Losses at iteration 53: {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 101.99248770536056}\n",
      "Losses at iteration 54: {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 131.16749338350306}\n",
      "Losses at iteration 55: {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 119.96121464678326}\n",
      "Losses at iteration 56: {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 105.87859910117696}\n",
      "Losses at iteration 57: {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 83.12450640220685}\n",
      "Losses at iteration 58: {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 111.74490272991837}\n",
      "Losses at iteration 59: {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 100.82244144812454}\n",
      "Losses at iteration 60: {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 112.98216457462873}\n",
      "Losses at iteration 61: {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 144.67808069528223}\n",
      "Losses at iteration 62: {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 110.44125202294262}\n",
      "Losses at iteration 63: {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 113.2544386956123}\n",
      "Losses at iteration 64: {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 85.57841191264849}\n",
      "Losses at iteration 65: {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 104.20715325688339}\n",
      "Losses at iteration 66: {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 102.78684268424078}\n",
      "Losses at iteration 67: {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 100.59687176867975}\n",
      "Losses at iteration 68: {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 91.29633867439894}\n",
      "Losses at iteration 69: {'tok2vec': 0.0, 'morphologizer': 0.0, 'parser': 0.0, 'ner': 99.77688262513989}\n"
     ]
    }
   ],
   "source": [
    "optimizer = nlp.resume_training()\n",
    "n_iter = 70  #\n",
    "\n",
    "for i in range(n_iter):\n",
    "    random.shuffle(TRAIN_DATA)\n",
    "    losses = {}\n",
    "    batches = minibatch(TRAIN_DATA, size=8)\n",
    "    for batch in batches:\n",
    "        texts, annotations = zip(*batch)\n",
    "        examples = [Example.from_dict(nlp.make_doc(text), ann) for text, ann in zip(texts, annotations)]\n",
    "        nlp.update(examples, drop=0.3, losses=losses)\n",
    "    print(f\"Losses at iteration {i}: {losses}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f688f072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель сохранена в папке street_modelF\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"street_modelF\"\n",
    "nlp.to_disk(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d90ca520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "На углу Peresechenie\n",
      "Байтурсынова Street\n",
      "Фурманова Street\n"
     ]
    }
   ],
   "source": [
    "text = \"На углу Байтурсынова и Фурманова обнаружена проблема.\"\n",
    "doc = nlp(text)\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7722a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ebaf7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_overlapping_entities(train_data):\n",
    "    cleaned_data = []\n",
    "    for text, annotations in train_data:\n",
    "        entities = annotations[\"entities\"]\n",
    "        entities = sorted(entities, key=lambda x: x[0]) \n",
    "        non_overlapping_entities = []\n",
    "        prev_start, prev_end = -1, -1\n",
    "\n",
    "        for start, end, label in entities:\n",
    "            if start >= prev_end:  # добавляем, если нет пересечения\n",
    "                non_overlapping_entities.append((start, end, label))\n",
    "                prev_start, prev_end = start, end\n",
    "            else:\n",
    "                print(f\"Overlap detected and removed: {(start, end, label)} in text: {text}\")\n",
    "\n",
    "        cleaned_data.append((text, {\"entities\": non_overlapping_entities}))\n",
    "\n",
    "    return cleaned_data\n",
    "\n",
    "# Применяем функцию к данным\n",
    "TRAIN_DATA = remove_overlapping_entities(TRAIN_DATA)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
